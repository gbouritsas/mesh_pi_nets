{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from lib import mesh_sampling\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "from facemesh import FaceData\n",
    "import time\n",
    "import pickle\n",
    "import trimesh\n",
    "\n",
    "try:\n",
    "    import psbody.mesh\n",
    "    found = True\n",
    "except ImportError:\n",
    "    found = False\n",
    "if found:\n",
    "    from psbody.mesh import Mesh, MeshViewer, MeshViewers\n",
    "\n",
    "from autoencoder_dataset import autoencoder_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from spiral_utils import get_adj_trigs, generate_spirals\n",
    "from models import SpiralAutoencoder, SpiralAutoencoder_extra_conv\n",
    "\n",
    "from test_funcs import test_autoencoder_dataloader\n",
    "\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "meshpackage = 'trimesh'\n",
    "root_dir = '/data/gb318/datasets/'\n",
    "\n",
    "name = ''\n",
    "dataset = 'DFAUST'    \n",
    "\n",
    "GPU = True\n",
    "device_idx = 9\n",
    "torch.cuda.get_device_name(device_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "generative_model = 'autoencoder'\n",
    "dilation_flag = False\n",
    "hardcode_down_ref = False\n",
    "downsample_method = 'COMA_downsample' # choose'COMA_downsample' or 'meshlab_downsample'\n",
    "downsample_config = ''\n",
    "\n",
    "if dataset == 'COMA':\n",
    "    reference_mesh_file = os.path.join(root_dir, dataset,'preprocessed/templates/template.obj')\n",
    "    downsample_directory = os.path.join(root_dir, dataset,'preprocessed/templates',downsample_method,downsample_config)\n",
    "elif dataset == 'DFAUST':\n",
    "    reference_mesh_file = os.path.join(root_dir, dataset,'template/template.obj')\n",
    "    downsample_directory = os.path.join(root_dir, dataset,'template',downsample_method,downsample_config)\n",
    "    \n",
    "ds_factors = [4, 4, 4, 4]\n",
    "step_sizes = [1, 1, 1, 1, 1]\n",
    "filter_sizes_enc = [[3, 16, 16, 16, 32],[[],[],[],[],[]]]\n",
    "filter_sizes_dec = [[32, 32, 16, 16, 3],[[],[],[],[],[]]]\n",
    "if dilation_flag:\n",
    "    dilation=[2, 2, 2, 1, 1] \n",
    "else:\n",
    "    dilation = None\n",
    "\n",
    "args = {'generative_model': generative_model,\n",
    "        'name': name, 'data': os.path.join(root_dir, dataset, 'preprocessed',name),\n",
    "        'results_folder':  os.path.join(root_dir, dataset,'results/higher_order_'+ generative_model,\n",
    "                                        downsample_method, downsample_config, 'TPAMI',\n",
    "                                        '2nd_order_full_norm_final'),\n",
    "        'reference_mesh_file':reference_mesh_file, 'downsample_directory': downsample_directory,\n",
    "        'checkpoint_file': 'checkpoint',\n",
    "        'seed':2, \n",
    "        'filter_sizes_enc': filter_sizes_enc, 'filter_sizes_dec': filter_sizes_dec,\n",
    "        'nz':16,\n",
    "        'ds_factors': ds_factors, 'step_sizes' : step_sizes, 'dilation': dilation,\n",
    "        'injection': True, 'residual': False, 'order': 2, \n",
    "        'normalize': 'final', 'model': 'full', 'activation': 'elu',\n",
    "        'nVal': 100, 'normalization': True,\n",
    "        'mm_constant': 1000}\n",
    "\n",
    "if generative_model == 'autoencoder':\n",
    "    args['results_folder'] = os.path.join(args['results_folder'],\\\n",
    "                                          'latent_'+str(args['nz']))\n",
    "    \n",
    "if not os.path.exists(os.path.join(args['results_folder'])):\n",
    "    os.makedirs(os.path.join(args['results_folder']))\n",
    "\n",
    "summary_path = os.path.join(args['results_folder'],'summaries',args['name'])\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)  \n",
    "    \n",
    "checkpoint_path = os.path.join(args['results_folder'],'checkpoints', args['name'])\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "    \n",
    "samples_path = os.path.join(args['results_folder'],'samples', args['name'])\n",
    "if not os.path.exists(samples_path):\n",
    "    os.makedirs(samples_path)\n",
    "    \n",
    "prediction_path = os.path.join(args['results_folder'],'predictions', args['name'])\n",
    "if not os.path.exists(prediction_path):\n",
    "    os.makedirs(prediction_path)\n",
    "\n",
    "if not os.path.exists(downsample_directory):\n",
    "    os.makedirs(downsample_directory)\n",
    "\n",
    "\n",
    "if hardcode_down_ref:\n",
    "    if dataset == 'COMA' and downsample_method == 'COMA_downsample':\n",
    "        reference_points = [[3567,4051,4597],\n",
    "                            [1010,1081,1170],\n",
    "                            [256, 276, 295],\n",
    "                            [11, 69, 74],\n",
    "                            [17, 17, 17]]\n",
    "    elif dataset == 'COMA' and downsample_method == 'meshlab_downsample' and\\\n",
    "            downsample_config == 'preserve_topology=True_preserve_boundary=False':\n",
    "        reference_points = [[3567, 4051, 4597],\n",
    "                             [1105, 1214, 1241],\n",
    "                             [289, 310, 318],\n",
    "                             [70, 80, 85],\n",
    "                             [2, 19, 24]]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "else:\n",
    "    if dataset == 'COMA':\n",
    "        reference_points = [[3567,4051,4597]] \n",
    "    elif dataset == 'mein3d' or dataset == 'mein3d_texture':\n",
    "        reference_points = [[23822]] \n",
    "    elif dataset == 'DFAUST':\n",
    "        reference_points = [[414]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data .. \n",
      "Loading Transform Matrices ..\n",
      "Calculating reference points for downsampled versions..\n",
      "spiral generation for hierarchy 0 (6890 vertices) finished\n",
      "spiral generation for hierarchy 1 (1723 vertices) finished\n",
      "spiral generation for hierarchy 2 (431 vertices) finished\n",
      "spiral generation for hierarchy 3 (108 vertices) finished\n",
      "spiral generation for hierarchy 4 (27 vertices) finished\n",
      "spiral sizes for hierarchy 0:  8\n",
      "spiral sizes for hierarchy 1:  9\n",
      "spiral sizes for hierarchy 2:  9\n",
      "spiral sizes for hierarchy 3:  9\n",
      "spiral sizes for hierarchy 4:  10\n",
      "cuda:9\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args['seed'])\n",
    "print(\"Loading data .. \")\n",
    "if not os.path.exists(args['data']+'/mean.npy') or not os.path.exists(args['data']+'/std.npy'):\n",
    "    facedata = FaceData(nVal=args['nVal'], train_file=args['data']+'/train.npy',\n",
    "                             test_file=args['data']+'/test.npy', reference_mesh_file=args['reference_mesh_file'],\n",
    "                             pca_n_comp=args['nz'], normalization = args['normalization'],\\\n",
    "                             meshpackage = meshpackage, load_flag = True)\n",
    "    np.save(args['data']+'/mean.npy', facedata.mean)\n",
    "    np.save(args['data']+'/std.npy', facedata.std)\n",
    "else:\n",
    "    facedata = FaceData(nVal=args['nVal'], train_file=args['data']+'/train.npy',\\\n",
    "                        test_file=args['data']+'/test.npy', reference_mesh_file=args['reference_mesh_file'],\\\n",
    "                        pca_n_comp=args['nz'], normalization = args['normalization'],\\\n",
    "                        meshpackage = meshpackage, load_flag = False)\n",
    "    facedata.mean = np.load(args['data']+'/mean.npy')\n",
    "    facedata.std = np.load(args['data']+'/std.npy')\n",
    "    facedata.n_vertex = facedata.mean.shape[0]\n",
    "    facedata.n_features = facedata.mean.shape[1]\n",
    "\n",
    "if not os.path.exists(os.path.join(args['downsample_directory'],'downsampling_matrices.pkl')):\n",
    "    if facedata.meshpackage == 'trimesh':\n",
    "        raise NotImplementedError\n",
    "    print(\"Generating Transform Matrices ..\")\n",
    "\n",
    "\n",
    "    if downsample_method == 'COMA_downsample':\n",
    "        M,A,D,U,F = mesh_sampling.generate_transform_matrices(facedata.reference_mesh, args['ds_factors'])\n",
    "    elif downsample_method == 'meshlab_downsample':\n",
    "        M,A,D,U,F = mesh_sampling.generate_transform_matrices_given_downsamples(facedata.reference_mesh,                                                                                args['downsample_directory'],                                                                                len(args['ds_factors']))\n",
    "    else:\n",
    "        raise NotImplementedError(downsample_method)\n",
    "        \n",
    "    with open(os.path.join(args['downsample_directory'],'downsampling_matrices.pkl'), 'wb') as fp:\n",
    "        M_verts_faces = [(M[i].v, M[i].f) for i in range(len(M))]\n",
    "        pickle.dump({'M_verts_faces':M_verts_faces,'A':A,'D':D,'U':U,'F':F}, fp)\n",
    "else:\n",
    "    print(\"Loading Transform Matrices ..\")\n",
    "    with open(os.path.join(args['downsample_directory'],'downsampling_matrices.pkl'), 'rb') as fp:\n",
    "        downsampling_matrices = pickle.load(fp,encoding = 'latin1')\n",
    "            \n",
    "    M_verts_faces = downsampling_matrices['M_verts_faces']\n",
    "    if facedata.meshpackage == 'mpi-mesh':\n",
    "        M = [Mesh(v=M_verts_faces[i][0], f=M_verts_faces[i][1]) for i in range(len(M_verts_faces))]\n",
    "    elif facedata.meshpackage == 'trimesh':\n",
    "        M = [trimesh.base.Trimesh(vertices=M_verts_faces[i][0], faces=M_verts_faces[i][1], process = False)             for i in range(len(M_verts_faces))]\n",
    "    A = downsampling_matrices['A']\n",
    "    D = downsampling_matrices['D']\n",
    "    U = downsampling_matrices['U']\n",
    "    F = downsampling_matrices['F']\n",
    "        \n",
    "\n",
    "if not hardcode_down_ref:\n",
    "    print(\"Calculating reference points for downsampled versions..\")\n",
    "    for i in range(len(args['ds_factors'])):\n",
    "        if facedata.meshpackage == 'mpi-mesh':\n",
    "            dist = euclidean_distances(M[i+1].v, M[0].v[reference_points[0]])\n",
    "        elif facedata.meshpackage == 'trimesh':\n",
    "            dist = euclidean_distances(M[i+1].vertices, M[0].vertices[reference_points[0]])\n",
    "        reference_points.append(np.argmin(dist,axis=0).tolist())\n",
    "\n",
    "if facedata.meshpackage == 'mpi-mesh':\n",
    "    sizes = [x.v.shape[0] for x in M]\n",
    "elif facedata.meshpackage == 'trimesh':\n",
    "    sizes = [x.vertices.shape[0] for x in M]\n",
    "Adj, Trigs = get_adj_trigs(A, F, facedata.reference_mesh, meshpackage = facedata.meshpackage)\n",
    "\n",
    "spirals_np, spiral_sizes,spirals = generate_spirals(args['step_sizes'], M, Adj, Trigs, \\\n",
    "                                                    reference_points = reference_points, \\\n",
    "                                                    dilation = args['dilation'], random = False, \\\n",
    "                                                    meshpackage = facedata.meshpackage, counter_clockwise = True)\n",
    "\n",
    "bU = []\n",
    "bD = []\n",
    "for i in range(len(D)):\n",
    "    d = np.zeros((1,D[i].shape[0]+1,D[i].shape[1]+1))\n",
    "    u = np.zeros((1,U[i].shape[0]+1,U[i].shape[1]+1))\n",
    "    d[0,:-1,:-1] = D[i].todense()\n",
    "    u[0,:-1,:-1] = U[i].todense()\n",
    "    d[0,-1,-1] = 1\n",
    "    u[0,-1,-1] = 1\n",
    "    bD.append(d)\n",
    "    bU.append(u)\n",
    "    \n",
    "# pytorch stuff\n",
    "\n",
    "torch.manual_seed(args['seed'])\n",
    "\n",
    "if GPU:\n",
    "    device = torch.device(\"cuda:\"+str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)\n",
    "\n",
    "tspirals = [torch.from_numpy(s).long().to(device) for s in spirals_np]\n",
    "tD = [torch.from_numpy(s).float().to(device) for s in bD]\n",
    "tU = [torch.from_numpy(s).float().to(device) for s in bU]\n",
    "\n",
    "dataset_test = autoencoder_dataset(root_dir = args['data'], points_dataset = 'test',\n",
    "                                          facedata = facedata,\n",
    "                                          normalization = args['normalization'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint from file /data/gb318/datasets/DFAUST/results/higher_order_autoencoder/COMA_downsample/TPAMI/1st_order/latent_16/checkpoints/checkpoint.pth.tar\n",
      "loading checkpoint from file /data/gb318/datasets/DFAUST/results/higher_order_autoencoder/COMA_downsample/TPAMI/2nd_order_full_norm_final/latent_16/checkpoints/checkpoint.pth.tar\n",
      "loading checkpoint from file /data/gb318/datasets/DFAUST/results/higher_order_autoencoder/COMA_downsample/TPAMI/3rd_order_full_norm_2nd/latent_16/checkpoints/checkpoint.pth.tar\n",
      "loading checkpoint from file /data/gb318/datasets/DFAUST/results/higher_order_autoencoder/COMA_downsample/TPAMI/4th_order_full_norm_2nd/latent_16/checkpoints/checkpoint.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# shape_index = 1000\n",
    "# shape_index = 1169\n",
    "# shape_index = 2345\n",
    "# shape_index = 4500\n",
    "# shape_index = 3500\n",
    "# shape_index = 1900\n",
    "# shape_index = 3218 \n",
    "\n",
    "shapedata_mean = torch.Tensor(facedata.mean).to(device)\n",
    "shapedata_std = torch.Tensor(facedata.std).to(device)\n",
    "template = trimesh.load(args['reference_mesh_file'], process = False)\n",
    "\n",
    "x_recons = []\n",
    "error_norms = []\n",
    "index = []\n",
    "base_results_folder = os.path.join(root_dir, dataset,'results', \n",
    "                                        'higher_order_{}'.format(generative_model),\n",
    "                                        downsample_method, downsample_config, 'TPAMI')\n",
    "argument_list = [['1st_order', False, False, 2, 'linear', None],\n",
    "                 ['2nd_order_full_norm_final', True, False, 2, 'full', 'final'],\n",
    "                 ['3rd_order_full_norm_2nd', True, False, 3, 'full', '2nd'],\n",
    "                 ['4th_order_full_norm_2nd', True, False, 4, 'full', '2nd']]\n",
    "\n",
    "for shape_index in [4500]:\n",
    "    \n",
    "    x = dataset_test[shape_index]['points'].to(device).unsqueeze(0)\n",
    "    if dataset_test.dummy_node:\n",
    "        x_unnorm = x[:,:-1]\n",
    "    x_unnorm = ((x_unnorm * shapedata_std + shapedata_mean) * args['mm_constant']).squeeze()\n",
    "    template.vertices = x_unnorm.cpu().numpy()\n",
    "    trimesh.exchange.export.export_mesh(template, \n",
    "                                        os.path.join(base_results_folder, 'errors', \n",
    "                                                     'gt_shape_{}_errors.obj'.format(shape_index)));\n",
    "    for i, arguments in enumerate(argument_list):\n",
    "\n",
    "        args.update({'results_folder': os.path.join(base_results_folder, arguments[0], 'latent_{}'.format(args['nz'])),\n",
    "                     'injection': arguments[1], 'residual': arguments[2], \n",
    "                     'order': arguments[3], 'model': arguments[4], 'normalize': arguments[5]})\n",
    "        checkpoint_path = os.path.join(args['results_folder'],'checkpoints', args['name'])\n",
    "        checkpoint_full_path = os.path.join(checkpoint_path, '{}.pth.tar'.format(args['checkpoint_file']))\n",
    "\n",
    "        model = SpiralAutoencoder_extra_conv(filters_enc = args['filter_sizes_enc'],   \n",
    "                                             filters_dec = args['filter_sizes_dec'],\n",
    "                                             latent_size=args['nz'],\n",
    "                                             sizes=sizes,\n",
    "                                             spiral_sizes=spiral_sizes,\n",
    "                                             spirals=tspirals,\n",
    "                                             D=tD, U=tU,device=device,\n",
    "                                             injection = args['injection'],\n",
    "                                             residual = args['residual'],\n",
    "                                             order = args['order'],\n",
    "                                             normalize = args['normalize'],\n",
    "                                             model = args['model'],\n",
    "                                             activation = args['activation']).to(device).eval()\n",
    "\n",
    "\n",
    "        print('loading checkpoint from file {}'.format(checkpoint_full_path))\n",
    "        checkpoint_dict = torch.load(checkpoint_full_path,map_location=device)\n",
    "        model.load_state_dict(checkpoint_dict['autoencoder_state_dict'])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_recon = model(x)  \n",
    "            if dataset_test.dummy_node:\n",
    "                x_recon = x_recon[:,:-1]\n",
    "            x_recon = ((x_recon * shapedata_std + shapedata_mean) * args['mm_constant']).squeeze()\n",
    "            x_recons.append(x_recon)\n",
    "            error_norms.append(torch.sqrt(torch.sum((x_recon - x_unnorm)**2,axis=1)))\n",
    "            index.append(shape_index)\n",
    "\n",
    "\n",
    "error_all = torch.cat((error_norms),0)\n",
    "clr = trimesh.visual.color.interpolate(error_all.cpu().numpy(),color_map='inferno_r')\n",
    "n = 0\n",
    "for i, x_recon in enumerate(x_recons):\n",
    "    template.vertices = x_recon.cpu().numpy()\n",
    "    template.visual = trimesh.visual.create_visual(vertex_colors = clr[n:n+x_recon.shape[0],:])\n",
    "    trimesh.exchange.export.export_mesh(template, \n",
    "                                        os.path.join(base_results_folder, 'errors', \n",
    "                                                     '{}_shape_{}_errors.obj'.format(argument_list[i%len(argument_list)][0], index[i])));\n",
    "    n += x_recon.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,1))\n",
    "fig.subplots_adjust(bottom=0.5)\n",
    "\n",
    "cmap = mpl.cm.inferno_r\n",
    "norm = mpl.colors.Normalize(vmin=error_all.min(), vmax=error_all.max())\n",
    "\n",
    "fig.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap),\n",
    "             cax=ax, orientation='horizontal', label='mm')\n",
    "plt.savefig(os.path.join(base_results_folder, 'errors', 'colorbar.png'), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
